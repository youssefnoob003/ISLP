{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee542c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "college = pd.read_csv(\"../../data/College.csv\")\n",
    "college = college.rename({\"Unnamed: 0\": \"College\"}, axis=1)\n",
    "college = college.set_index(\"College\")\n",
    "\n",
    "college_train, college_valid = train_test_split(college,\n",
    "                                         test_size=0.2,\n",
    "                                         random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37eb32d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(48094)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.Apps.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abf1de2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1182113.6667500068)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from ISLP.models import ModelSpec as MS \n",
    "import numpy as np\n",
    "\n",
    "X_train = MS(college.columns.drop([\"Apps\", \"Private\"])).fit_transform(college_train)\n",
    "Y_train = college_train[\"Apps\"]\n",
    "\n",
    "X_valid = MS(college.columns.drop([\"Apps\", \"Private\"])).fit_transform(college_valid)\n",
    "Y_valid = college_valid[\"Apps\"]\n",
    "\n",
    "model = sm.OLS(Y_train, X_train)\n",
    "results = model.fit()\n",
    "\n",
    "Y_hat = results.predict(X_valid)\n",
    "\n",
    "np.mean((Y_valid - Y_hat)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a9385",
   "metadata": {},
   "source": [
    "The validation mean squared error (MSE) of approximately 1,182,114 in the OLS model initially appears large, but when contextualized against the response variable **Apps**, it is more interpretable. Given that the maximum number of applications is around 48,000, this corresponds to a root mean squared error (RMSE) of roughly 1,087 applications, which is about 2.3% of the maximum and likely around 10â€“15% of the mean. While this level of error may be acceptable for exploratory modeling or rough predictions, it suggests room for improvement, especially if the goal is accurate forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0a39124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1182113.6536551272)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.linear_model as skl\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.model_selection as skm\n",
    "\n",
    "lambdas = 10**np.linspace(8, -2, 100) / Y_train.std()\n",
    "\n",
    "scaler = StandardScaler(with_mean=True,  with_std=True)\n",
    "\n",
    "K = 5\n",
    "kfold = skm.KFold(K,\n",
    "                  random_state=0,\n",
    "                  shuffle=True)\n",
    "\n",
    "\n",
    "lasso = skl.ElasticNetCV(alphas=lambdas, \n",
    "                           l1_ratio=1,\n",
    "                           cv=kfold)\n",
    "\n",
    "pipe = Pipeline(steps=[('scaler', scaler),\n",
    "                         ('lasso', lasso)])\n",
    "pipe.fit(X_train, Y_train)\n",
    "\n",
    "Y_hat = pipe.predict(X_valid)\n",
    "\n",
    "np.mean((Y_valid - Y_hat)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b69c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  4.20865668e+03, -1.04060381e+03,  1.03025296e+03,\n",
       "       -3.73436230e+02,  4.54799103e+02,  1.05347953e+02, -4.09341509e+02,\n",
       "        1.63795085e+02,  1.32378568e+00, -8.65477980e+00, -1.39124431e+02,\n",
       "       -1.55157539e+01,  5.86738679e+01, -2.36632326e+01,  2.88135210e+02,\n",
       "        1.35564538e+02])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_lasso = pipe.named_steps['lasso']\n",
    "tuned_lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ace4f2",
   "metadata": {},
   "source": [
    "Using the lasso, all of the coefficients were selected, likely due to multicollinearity in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8463f860",
   "metadata": {},
   "source": [
    "I used RidgeCV instead of ElasticNetCV with l1_ratio=0 because RidgeCV is optimized specifically for that. Using RidgeCV ensures more stable and efficient fitting for pure Ridge models compared to forcing ElasticNetCV to behave like Ridge by setting l1_ratio=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b55ebe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1171481.180113388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "ridge = RidgeCV(alphas=lambdas, cv=kfold)\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('ridge', ridge)])\n",
    "pipe.fit(X_train, Y_train)\n",
    "\n",
    "Y_hat = pipe.predict(X_valid)\n",
    "mse = np.mean((Y_valid - Y_hat)**2)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be640d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  4.15452579e+03, -9.59256224e+02,  1.00829165e+03,\n",
       "       -3.56382468e+02,  4.23510221e+02,  1.05074449e+02, -4.01177300e+02,\n",
       "        1.66750474e+02,  1.68967701e+00, -9.25586209e+00, -1.36324194e+02,\n",
       "       -1.74295418e+01,  5.96773362e+01, -2.84029748e+01,  2.90316087e+02,\n",
       "        1.36317895e+02])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_ridge = pipe.named_steps['ridge']\n",
    "tuned_ridge.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694d945f",
   "metadata": {},
   "source": [
    "The ridge regression model achieved a slightly lower test MSE (1,171,481) compared to both the lasso (1,182,114) and ordinary least squares regression (1,182,114), indicating a modest improvement in predictive performance. This suggests that while the linear model may suffer from multicollinearity or overfitting, the L2 regularization in ridge regression helped stabilize the coefficients without setting any to zero, leading to a better generalization on the validation set. However, the improvement is small, implying that regularization had limited effect in this case, possibly due to a weak signal or all predictors contributing similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96a49928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected number of principal components (M): 16\n",
      "Test MSE: 1182113.666749987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "linreg = skl.LinearRegression()\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "\n",
    "pipe = Pipeline([('scaler', scaler),\n",
    "                 ('pca', pca),\n",
    "                 ('linreg', linreg)])\n",
    "\n",
    "max_components = min(X_train.shape[0] * (kfold.get_n_splits() - 1) // kfold.get_n_splits(), X_train.shape[1])\n",
    "\n",
    "param_grid = {'pca__n_components': range(1, max_components + 1)}\n",
    "\n",
    "grid = skm.GridSearchCV(pipe,\n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "\n",
    "grid.fit(X_train, Y_train)\n",
    "\n",
    "best_M = grid.best_params_['pca__n_components']\n",
    "print(f\"Selected number of principal components (M): {best_M}\")\n",
    "\n",
    "Y_pred = grid.predict(X_valid)\n",
    "\n",
    "test_mse = np.mean((Y_valid - Y_pred)**2)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a9b6b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected number of principal components (M): 16\n",
      "Test MSE: 1182113.6667499894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "pls = PLSRegression(n_components=2, \n",
    "                    scale=True)\n",
    "\n",
    "param_grid = {'n_components': range(1, max_components + 1)}\n",
    "\n",
    "grid = skm.GridSearchCV(pls,\n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X_train, Y_train)\n",
    "\n",
    "best_M = grid.best_params_['n_components']\n",
    "print(f\"Selected number of principal components (M): {best_M}\")\n",
    "\n",
    "Y_pred = grid.predict(X_valid)\n",
    "\n",
    "test_mse = np.mean((Y_valid - Y_pred)**2)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3fd49a",
   "metadata": {},
   "source": [
    "Both PCR (Principal Components Regression) and PLS (Partial Least Squares) selected 16 components and produced virtually identical test MSEs (\\~1,182,114), indicating no meaningful performance difference between the two methods in this case. This outcome suggests that the dominant variance in the predictor space (captured by PCA) aligns closely with the directions most relevant for predicting the response, which is also what PLS attempts to optimize. As a result, both models arrived at similar solutions despite their conceptual differencesâ€”PCR focuses purely on explaining predictor variance, while PLS incorporates the response during component extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac0efa4",
   "metadata": {},
   "source": [
    "Overall, the modeling results on this dataset suggest that regularization and dimension reduction techniques offer only marginal improvements over standard linear regression. The test MSEs from ridge regression, lasso, PCR, and PLS are all very close to one another, with ridge slightly outperforming the others. This indicates that the predictors are likely moderately multicollinear, but not in a way that severely impacts the performance of ordinary least squares. The fact that lasso did not shrink any coefficients to zero, and both PCR and PLS selected the maximum number of components, further supports the idea that no strong subset of predictors dominates the relationship with the response. Thus, while regularization and dimension reduction offer robustness, the underlying signal in the data is relatively diffuse across predictors, and no method provides a clear advantage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
