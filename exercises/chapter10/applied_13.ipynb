{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a18293c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP.torch.imdb import (load_tensor,\n",
    "                             load_sequential)\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from ISLP.torch import SimpleDataModule, SimpleModule, ErrorTracker\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchinfo import summary\n",
    "from torch.optim import RMSprop\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "(imdb_seq_train,\n",
    " imdb_seq_test) = load_sequential(root='data/IMDB')\n",
    "padded_sample = np.asarray(imdb_seq_train.tensors[0][0])\n",
    "sample_review = padded_sample[padded_sample > 0][:12]\n",
    "\n",
    "max_num_workers=10\n",
    "(imdb_train,\n",
    " imdb_test) = load_tensor(root='data/IMDB')\n",
    "imdb_dm = SimpleDataModule(imdb_train,\n",
    "                           imdb_test,\n",
    "                           validation=2000,\n",
    "                           num_workers=min(6, max_num_workers),\n",
    "                           batch_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b9f5577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size=16):\n",
    "        super(IMDBModel, self).__init__()\n",
    "        self.dense1 = nn.Linear(input_size, hidden_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        val = x\n",
    "        for _map in [self.dense1,\n",
    "                     self.activation,\n",
    "                     self.dense2,\n",
    "                     self.activation,\n",
    "                     self.output]:\n",
    "            val = _map(val)\n",
    "        return torch.flatten(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5afe6d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "IMDBModel                                [25000, 10003]            [25000]                   --\n",
       "â”œâ”€Linear: 1-1                            [25000, 10003]            [25000, 16]               160,064\n",
       "â”œâ”€ReLU: 1-2                              [25000, 16]               [25000, 16]               --\n",
       "â”œâ”€Linear: 1-3                            [25000, 16]               [25000, 16]               272\n",
       "â”œâ”€ReLU: 1-4                              [25000, 16]               [25000, 16]               --\n",
       "â”œâ”€Linear: 1-5                            [25000, 16]               [25000, 1]                17\n",
       "===================================================================================================================\n",
       "Total params: 160,353\n",
       "Trainable params: 160,353\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 4.01\n",
       "===================================================================================================================\n",
       "Input size (MB): 1000.30\n",
       "Forward/backward pass size (MB): 6.60\n",
       "Params size (MB): 0.64\n",
       "Estimated Total Size (MB): 1007.54\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_model = IMDBModel(imdb_test.tensors[0].size()[1])\n",
    "summary(imdb_model,\n",
    "        input_size=imdb_test.tensors[0].size(),\n",
    "        col_names=['input_size',\n",
    "                   'output_size',\n",
    "                   'num_params'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ec46036",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_optimizer = RMSprop(imdb_model.parameters(), lr=0.001)\n",
    "imdb_module = SimpleModule.binary_classification(\n",
    "                         imdb_model,\n",
    "                         optimizer=imdb_optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98cffbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type              | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | model | IMDBModel         | 160 K  | train\n",
      "1 | loss  | BCEWithLogitsLoss | 0      | train\n",
      "----------------------------------------------------\n",
      "160 K     Trainable params\n",
      "0         Non-trainable params\n",
      "160 K     Total params\n",
      "0.641     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    }
   ],
   "source": [
    "imdb_logger = CSVLogger('logs', name='IMDB')\n",
    "imdb_trainer = Trainer(deterministic=False,\n",
    "                       max_epochs=30,\n",
    "                       logger=imdb_logger,\n",
    "                       enable_progress_bar=False,\n",
    "                       callbacks=[ErrorTracker()])\n",
    "imdb_trainer.fit(imdb_module,\n",
    "                 datamodule=imdb_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b771ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "       Test metric             DataLoader 0\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "      test_accuracy         0.8494399785995483\n",
      "        test_loss            1.187672734260559\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[{'test_loss': 1.187672734260559, 'test_accuracy': 0.8494399785995483}]\n"
     ]
    }
   ],
   "source": [
    "test_results = imdb_trainer.test(imdb_module, datamodule=imdb_dm)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b77f0e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/sibouzitoun/Documents/AI/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type              | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | model | IMDBModel         | 160 K  | train\n",
      "1 | loss  | BCEWithLogitsLoss | 0      | train\n",
      "----------------------------------------------------\n",
      "160 K     Trainable params\n",
      "0         Non-trainable params\n",
      "160 K     Total params\n",
      "0.641     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/sibouzitoun/Documents/AI/.venv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (45) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "       Test metric             DataLoader 0\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "      test_accuracy         0.8465200066566467\n",
      "        test_loss           2.3962793350219727\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[{'test_loss': 2.3962793350219727, 'test_accuracy': 0.8465200066566467}]\n"
     ]
    }
   ],
   "source": [
    "imdb_model = IMDBModel(imdb_test.tensors[0].size()[1], hidden_size=32)\n",
    "imdb_trainer = Trainer(deterministic=False,\n",
    "                       max_epochs=30,\n",
    "                       enable_progress_bar=False,\n",
    "                       callbacks=[ErrorTracker()])\n",
    "imdb_trainer.fit(imdb_module,\n",
    "                 datamodule=imdb_dm)\n",
    "\n",
    "test_results = imdb_trainer.test(imdb_module, datamodule=imdb_dm)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ea79230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type              | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | model | IMDBModel         | 160 K  | train\n",
      "1 | loss  | BCEWithLogitsLoss | 0      | train\n",
      "----------------------------------------------------\n",
      "160 K     Trainable params\n",
      "0         Non-trainable params\n",
      "160 K     Total params\n",
      "0.641     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "       Test metric             DataLoader 0\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "      test_accuracy         0.8445600271224976\n",
      "        test_loss            3.167004346847534\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "[{'test_loss': 3.167004346847534, 'test_accuracy': 0.8445600271224976}]\n"
     ]
    }
   ],
   "source": [
    "imdb_model = IMDBModel(imdb_test.tensors[0].size()[1], hidden_size=64)\n",
    "imdb_trainer = Trainer(deterministic=False,\n",
    "                       max_epochs=30,\n",
    "                       enable_progress_bar=False,\n",
    "                       callbacks=[ErrorTracker()])\n",
    "imdb_trainer.fit(imdb_module,\n",
    "                 datamodule=imdb_dm)\n",
    "\n",
    "test_results = imdb_trainer.test(imdb_module, datamodule=imdb_dm)\n",
    "print(test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
