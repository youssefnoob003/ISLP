{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daaf9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from ISLP import load_data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "NYSE = load_data('NYSE')\n",
    "cols = ['DJ_return', 'log_volume', 'log_volatility']\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    StandardScaler().fit_transform(NYSE[cols]),\n",
    "    columns=cols,\n",
    "    index=NYSE.index\n",
    ")\n",
    "\n",
    "lags = 5\n",
    "X_lagged = pd.concat([X.shift(i) for i in range(1, lags+1)], axis=1)\n",
    "X_lagged.columns = [f\"{col}_lag{i}\" for i in range(1, lags+1) for col in cols]\n",
    "X_lagged = X_lagged.dropna()\n",
    "Y = X.loc[X_lagged.index, 'log_volume']\n",
    "\n",
    "X_tensor = torch.tensor(X_lagged.values, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "train_size = int(0.8 * len(X_tensor))\n",
    "X_train, X_test = X_tensor[:train_size], X_tensor[train_size:]\n",
    "Y_train, Y_test = Y_tensor[:train_size], Y_tensor[train_size:]\n",
    "\n",
    "train_ds = TensorDataset(X_train, Y_train)\n",
    "test_ds = TensorDataset(X_test, Y_test)\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bcdb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonlinearARModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = NonlinearARModel(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c51be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f10b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R² (nonlinear AR): 0.3461\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_pred = model(X_test)\n",
    "    ss_res = ((Y_test - Y_pred)**2).sum()\n",
    "    ss_tot = ((Y_test - Y_test.mean())**2).sum()\n",
    "    r2_test = 1 - ss_res/ss_tot\n",
    "\n",
    "print(f\"Test R² (nonlinear AR): {r2_test.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6391aed9",
   "metadata": {},
   "source": [
    "The nonlinear AR model trained on the flattened lagged sequences achieved a **test R² of 0.346**, which is slightly lower than the linear AR model’s R² of 0.391. This indicates that, in this case, the nonlinear feedforward network does not improve predictive performance over the simpler linear model. One possible reason is that the underlying relationships in the lagged NYSE data are largely linear, so the added complexity of a nonlinear network does not provide additional explanatory power and may even introduce slight overfitting. Overall, while nonlinear models are flexible and can capture complex patterns, for this dataset a **linear AR model appears sufficient** and more robust."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
