{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f206e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset (assuming CSV)\n",
    "smarket = pd.read_csv(\"../../data/Smarket.csv\")\n",
    "\n",
    "# Encode Direction as 0/1\n",
    "le = LabelEncoder()\n",
    "smarket['Direction_encoded'] = le.fit_transform(smarket['Direction'])  # Up=1, Down=0\n",
    "\n",
    "# Features and target\n",
    "X = smarket[['Lag1','Lag2','Lag3','Lag4','Lag5','Volume']]\n",
    "y = smarket['Direction_encoded']\n",
    "\n",
    "# Train/test split (e.g., 2001 for training, 2002 for testing)\n",
    "train = smarket['Year'] == 2001\n",
    "test = smarket['Year'] == 2002\n",
    "\n",
    "X_train, X_test = X[train], X[test]\n",
    "y_train, y_test = y[train], y[test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "324e8f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Boosting: 0.508\n",
      "[[74 66]\n",
      " [58 54]]\n",
      "Bagging: 0.488\n",
      "[[71 69]\n",
      " [60 52]]\n",
      "Random Forest: 0.496\n",
      "[[76 64]\n",
      " [63 49]]\n",
      "Logistic Regression: 0.536\n",
      "[[115  25]\n",
      " [ 92  20]]\n",
      "BART Test Accuracy: 0.464\n",
      "[[75 65]\n",
      " [70 42]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from ISLP.bart import BART\n",
    "import numpy as np\n",
    "\n",
    "# --- Boosting ---\n",
    "boost = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.01, random_state=0)\n",
    "boost.fit(X_train, y_train)\n",
    "y_pred_boost = boost.predict(X_test)\n",
    "acc_boost = accuracy_score(y_test, y_pred_boost)\n",
    "\n",
    "# --- Bagging ---\n",
    "bag = BaggingClassifier(n_estimators=500, random_state=0)\n",
    "bag.fit(X_train, y_train)\n",
    "y_pred_bag = bag.predict(X_test)\n",
    "acc_bag = accuracy_score(y_test, y_pred_bag)\n",
    "\n",
    "# --- Random Forest ---\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# --- Logistic Regression ---\n",
    "logreg = LogisticRegression(max_iter=5000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_log = logreg.predict(X_test)\n",
    "acc_log = accuracy_score(y_test, y_pred_log)\n",
    "\n",
    "# --- BART ---\n",
    "X_train_bart = X_train.astype(np.float32)\n",
    "y_train_bart = y_train.astype(np.float32)\n",
    "X_test_bart = X_test.astype(np.float32)\n",
    "y_test_bart = y_test.astype(np.float32)\n",
    "\n",
    "bart_model = BART(random_state=0, burnin=50, ndraw=200)\n",
    "bart_model.fit(X_train_bart, y_train_bart)\n",
    "\n",
    "yhat_test = bart_model.predict(X_test_bart)  # continuous output\n",
    "y_pred_bart = (yhat_test > 0.5).astype(int)\n",
    "\n",
    "acc_bart = accuracy_score(y_test, y_pred_bart)\n",
    "\n",
    "# --- Confusion matrices ---\n",
    "cm_boost = confusion_matrix(y_test, y_pred_boost)\n",
    "cm_bag = confusion_matrix(y_test, y_pred_bag)\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "cm_log = confusion_matrix(y_test, y_pred_log)\n",
    "cm_bart = confusion_matrix(y_test, y_pred_bart)\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "print(f\"Boosting: {acc_boost:.3f}\")\n",
    "print(cm_boost)\n",
    "print(f\"Bagging: {acc_bag:.3f}\")\n",
    "print(cm_bag)\n",
    "print(f\"Random Forest: {acc_rf:.3f}\")\n",
    "print(cm_rf)\n",
    "print(f\"Logistic Regression: {acc_log:.3f}\")\n",
    "print(cm_log)\n",
    "print(f\"BART Test Accuracy: {acc_bart:.3f}\")\n",
    "print(cm_bart)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8146806",
   "metadata": {},
   "source": [
    "The confusion matrices and accuracies for the Smarket dataset illustrate how different modeling approaches handle this noisy financial time series. Logistic regression achieves the highest overall accuracy (**53.6%**) and correctly identifies a relatively large number of “Down” days (115), but it struggles with predicting “Up” days, with only 20 correct. Boosting, bagging, and random forests perform worse, with accuracies between **48.8–50.8%**, and their confusion matrices show that they tend to misclassify many days in both directions, reflecting overfitting to idiosyncratic patterns in the training data. BART performs the worst (**46.4%**), similarly showing poor separation between “Up” and “Down” days.\n",
    "\n",
    "The explanation lies in the characteristics of the Smarket data: the lagged returns and volume have only a weak predictive signal for the next day’s market direction, and the time series is dominated by noise. Ensemble methods like boosting and random forests, which are highly flexible and can capture nonlinear interactions, tend to **overfit the training data**, learning spurious fluctuations that do not generalize to the test set. Logistic regression, being simpler and linear, effectively captures the modest linear relationships without overfitting, which explains its slightly better performance. BART, despite its flexibility, also suffers from overfitting and possibly limited sampling in this implementation, which reduces its predictive accuracy. Overall, these results illustrate that in high-noise, weak-signal datasets, **simpler linear models may outperform more flexible ensemble methods**, even though the latter are theoretically more powerful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
